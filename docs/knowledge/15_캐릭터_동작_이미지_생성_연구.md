# **정체성의 설계자: ChatGPT-4o와 Imagen 4를 활용한 캐릭터 일관성 마스터클래스 (2025년)**

## **1부: 캐릭터 일관성의 기본 원칙** {#부-캐릭터-일관성의-기본-원칙}

생성형 AI 이미지 기술이 발전함에 따라, 단순히 아름다운 이미지를 만드는
것을 넘어 일관된 정체성을 가진 캐릭터를 다양한 상황과 동작 속에서
구현하는 것이 전문가 수준의 창작에서 핵심 과제로 떠올랐습니다. 이러한
일관성을 달성하기 위해서는 플랫폼별 기능을 익히기 전에, AI 모델이
\'정체성\'과 \'지시\'를 어떻게 해석하는지에 대한 근본적인 메커니즘을
이해해야 합니다. 이 원칙들은 모든 플랫폼에 걸쳐 적용되는 이론적 기반이
됩니다.

### **1.1. 프롬프트 해부: 캐릭터의 \'디지털 DNA\' 설계** {#프롬프트-해부-캐릭터의-디지털-dna-설계}

캐릭터 일관성을 확보하는 첫 단계는 즉흥적인 묘사에서 벗어나, 캐릭터의
모든 정보를 담은 정형화된 텍스트 블록, 즉 \'캐릭터 바이블\' 또는
\'디지털 DNA 템플릿\'을 구축하는 것입니다. 이는 캐릭터 정체성에 대한
단일 진실 공급원(Single Source of Truth) 역할을 하며, 모든 생성 과정의
기준점이 됩니다.

연구에 따르면, 성공적인 캐릭터 생성은 이미지 생성 이전에 상세한 프로필을
정의하는 것에서 시작됩니다. 이 프로필은 외모, 성격, 의상, 심지어
습관까지 포괄해야 합니다.^1^ 이 프로필은 핵심 외형, 착용 아이템, 스타일,
그리고 시나리오의 네 가지 주요 구성 요소로 체계화될 수 있습니다.^4^ 이때
사용되는 언어는 동의어를 피하고 절대적인 일관성을 유지해야 합니다. 예를
들어, \'갈색 트렌치코트\'라고 정했다면 이후에도 \'재킷\'이나 \'외투\'가
아닌 \'갈색 트렌치코트\'라는 표현을 고수해야 합니다.^5^

사용자 커뮤니티에서 발전된 \'DNA 템플릿\'과 같은 구조화된 프롬프트는
이러한 접근법을 극대화하는 강력한 프레임워크를 제공합니다.^6^ 이
템플릿은 단순히 외모를 나열하는 것을 넘어, 이미지의 종횡비, 전체적인
아트 스타일, 배경 설정, 캐릭터의 세부적인 신체 특징(피부톤, 얼굴형, 눈
모양 및 색상, 헤어스타일), 주요 의상과 이를 구별하기 위한 미세한
변형(예: 쌍둥이 자매 중 한 명은 리본을, 다른 한 명은 펜던트를 착용),
그리고 감정 상태까지 명시합니다.^6^

이러한 접근법은 단순한 프롬프트 작성을 넘어, 캐릭터를 일회성 묘사가 아닌
재사용 가능한 \'자산(Asset)\'으로 전환시키는 과정입니다. 사용자는 AI가
본질적으로 갖추지 못한 \'영속적인 캐릭터 객체\'라는 개념을 텍스트를 통해
시뮬레이션하는 것입니다. 이는 텍스트 기반의 \'DNA 템플릿\'에서 시작하여,
시각적 참조물인 \'이미지 업로드\', 그리고 특정 캐릭터에 특화된 모델을
훈련하는 \'LoRA 튜닝\'으로 이어지는 기술 발전의 첫 단계를 의미합니다. 이
발전 단계를 이해하는 것은 주어진 작업에 가장 적합한 기술을 선택하는 데
있어 매우 중요합니다.

다음 표는 효과적인 \'캐릭터 DNA\' 프롬프트 템플릿을 구성하는 핵심
요소들을 정리한 것입니다. 이는 사용자가 중요한 세부 사항을 놓치지 않고
체계적으로 캐릭터를 정의할 수 있도록 돕는 실용적인 도구입니다.^1^

**표 1: \'캐릭터 DNA\' 프롬프트 템플릿의 핵심 구성 요소**

| 카테고리          | 구성 요소                             | 예시 프롬프트 스니펫                                        |
|-------------------|---------------------------------------|-------------------------------------------------------------|
| **핵심 정체성**   | 이름, 나이, 역할, 성격                | Sir Aldric Veyne, a battle-scarred knight                   |
| **신체적 특징**   | 얼굴형, 눈 색상/모양, 헤어스타일/색상 | round face with soft cheeks, large almond-shaped hazel eyes |
| **대표 의상**     | 주요 의상, 색상 팔레트                | wears a traditional pastel pink dress                       |
| **액세서리**      | 구별 가능한 아이템 1, 아이템 2        | Hi wears a pink hair ribbon                                 |
| **스타일 정의**   | 아트 스타일, 조명 스타일              | soft anime watercolor style, with gentle linework           |
| **장면 매개변수** | 구도, 종횡비                          | cinematic horizontal composition with medium-wide shot      |

### **1.2. 확산 모델의 언어: 프롬프트 구조와 토큰 순서의 중요성** {#확산-모델의-언어-프롬프트-구조와-토큰-순서의-중요성}

키워드를 단순히 나열하는 것보다 구조화된 문장이 왜 더 효과적인지를
이해하려면, GPT-4o나 Imagen 4와 같은 트랜스포머 기반 모델이 프롬프트를
\'읽는\' 핵심 방식인 어텐션 메커니즘(Attention Mechanism)을 알아야
합니다.

확산 모델은 텍스트 프롬프트와 같은 조건부 입력에 따라 노이즈를
점진적으로 제거하여 이미지를 생성합니다.^7^ 이 과정에서 텍스트는
\'토큰(token)\'이라는 단위로 분해됩니다.^9^ 모델이 프롬프트의 문맥을
파악하는 핵심 기술이 바로 \'어텐션 메커니즘\'으로, 이는 각 토큰(단어)의
중요도에 가중치를 부여하여 어떤 단어가 다른 단어와 더 밀접하게
관련되는지를 계산합니다.^9^

이 메커니즘은 흔히 쿼리(Query), 키(Key), 밸류(Value)라는 세 가지 요소로
비유됩니다.^10^ 각 토큰은 자신이 찾아야 할 정보에 대한 \'쿼리\'를
보냅니다(예: \"나는 \'셔츠\'인데, 어떤 색과 결합해야 하지?\"). 다른
토큰들은 자신의 정보를 담은 \'키\'를 제시합니다(예: \"나는
\'파란색\'이라는 속성이다\"). 쿼리가 가장 관련성 높은 키를 찾으면, 해당
키에 연결된 \'밸류\'(실제 \'파란색\'이라는 개념)가 쿼리를 보낸 토큰에
적용됩니다.

이러한 메커니즘은 \'속성 혼합(attribute bleed)\'과 같은 일반적인 문제를
설명해 줍니다. 예를 들어, \"빨간 머리, 파란 셔츠(red hair, blue
shirt)\"라는 프롬프트가 파란색 기운이 도는 얼굴을 생성하는 경우가
있는데, 이는 어텐션 메커니즘이 \'파란색\'이라는 밸류를 \'머리\'나
\'얼굴\'이라는 키에 잘못 적용했기 때문입니다. 따라서 사용자의 역할은
단순히 특징을 나열하는 것이 아니라, 명확한 주어-서술어-목적어 구조의
문장을 사용하고 캐릭터, 행동, 배경 등의 섹션을 구분하여 프롬프트 구조를
설계함으로써 어텐션 메커니즘이 명확한 관계를 파악하도록 유도하는
것입니다.^12^ 이로써 프롬프트 작성은 \'그림 묘사\'에서 \'어텐션 맵
설계\'라는 더 높은 수준의 작업으로 격상되며, 이는 생성 결과물을
디버깅하는 강력한 사고의 틀을 제공합니다.

또한, 연구에 따르면 확산 과정의 각기 다른 타임스텝은 이미지의 다른
수준의 디테일에 민감하게 반응합니다. 노이즈가 많은 후반 타임스텝은
프롬프트의 핵심 의미와 같은 거시적, 의미론적 정보에 더 큰 영향을 받고,
노이즈가 적은 초반 타임스텝은 미세한 디테일을 처리하는 데
관여합니다.^13^ 이는 프롬프트의 구조와 내용이 이미지 생성의 전 과정에
걸쳐 계층적으로 영향을 미침을 시사합니다.

### **1.3. 보이지 않는 손: 해부학적, 스타일적 무결성을 위한 네거티브 프롬프트 마스터하기** {#보이지-않는-손-해부학적-스타일적-무결성을-위한-네거티브-프롬프트-마스터하기}

네거티브 프롬프트는 단순히 잘못된 결과를 수정하는 수동적 도구를 넘어,
사전에 오류를 방지하고 결과물의 품질을 보장하는 능동적 전략으로
활용되어야 합니다.

네거티브 프롬프트는 특히 손이나 얼굴과 같은 복잡한 인체 구조의 기형적
표현을 방지하는 데 필수적입니다.^14^ 또한, 원치 않는 아트 스타일의
혼합을 막거나(예: 2D 애니메이션 스타일 생성 시

negative prompt: photorealistic, 3D 사용) 구도를 제어하는 데에도
효과적으로 사용될 수 있습니다(예: negative prompt: cluttered,
messy).^15^

포지티브 프롬프트가 결과물의 \'창의적 상한선\'(이미지가 무엇이 될 수
있는가)을 정의한다면, 네거티브 프롬프트는 \'품질의 하한선\'(이미지가
무엇이 되어서는 안 되는가)을 설정합니다. 숙련된 사용자들은 문제가 발생할
때마다 네거티브 프롬프트를 추가하는 반응적인 방식에서 벗어나, 일반적인
실패 유형을 방지하기 위한 \'범용 네거티브 프롬프트 라이브러리\'를
구축하여 모든 생성 작업에 선제적으로 적용합니다.^15^ 이는 일종의
자동화된 품질 관리 시스템으로 작동하여 작업 효율성을 크게 향상시킵니다.
개인화된 강력한 네거티브 프롬프트 템플릿을 만들어두고, 대부분의 캐릭터
생성 명령어에 기본적으로 추가하는 것이 바람직한 워크플로우입니다.

다음 표는 AI 이미지 생성 시 발생하는 주요 문제 영역을 해결하기 위한
포괄적인 네거티브 프롬프트 라이브러리를 제공합니다. 이는 여러 자료에서
언급된 키워드들을 종합하여 사용자가 즉시 활용할 수 있는 자원으로
구성되었습니다.^15^

**표 2: 포괄적인 네거티브 프롬프트 라이브러리**

| 문제 영역                   | 구체적 이슈                            | 네거티브 프롬프트 키워드                                                           |
|-----------------------------|----------------------------------------|------------------------------------------------------------------------------------|
| **해부학 및 비율**          | 기형적인 손/손가락, 불쾌한 골짜기 얼굴 | extra fingers, mutated hands, fused fingers, deformed, asymmetrical, plastic, waxy |
| **이미지 품질 및 아티팩트** | 흐릿함/픽셀화, 원치 않는 객체          | low quality, blurry, noisy, jpeg artifacts, cluttered, messy, crowded              |
| **구도 및 스타일**          | 스타일 오염, 평면적인 구도             | realistic, 3D (2D 스타일용), flat design, 2d art                                   |
| **텍스트 및 워터마크**      | 의미 없는 텍스트, 서명                 | text, watermark, signature, logo, UI elements                                      |

## **2부: ChatGPT-4o에서의 캐릭터 일관성 마스터하기** {#부-chatgpt-4o에서의-캐릭터-일관성-마스터하기}

OpenAI의 생태계는 GPT-4o의 대화형, 다중모드(multimodal) 특성을 기반으로
한 *암묵적(implicit)* 일관성 워크플로우에 강점을 보입니다. 이는 사용자가
AI와 상호작용하며 점진적으로 결과물을 완성해나가는 방식입니다.

### **2.1. GPT-4o의 강점: 네이티브 다중모드를 활용한 추론적 일관성** {#gpt-4o의-강점-네이티브-다중모드를-활용한-추론적-일관성}

GPT-4o의 아키텍처는 이전 세대의 이미지 생성기와 근본적으로 다릅니다. 이
차이점을 이해하는 것이 플랫폼의 잠재력을 최대한 활용하는 열쇠입니다.

GPT-4o는 OpenAI 최초의 네이티브 다중모드 모델로, 텍스트와 이미지를
별개의 모델이 아닌 단일 통합 신경망으로 처리합니다.^19^ 이러한 통합
아키텍처는 모델이 대화의 전체 맥락을 기억하는 \'시각적 메모리\'를 갖게
하여, 동일한 채팅 세션 내에서 여러 이미지에 걸쳐 스타일과 캐릭터의
일관성을 자연스럽게 유지하도록 돕습니다.^19^ 또한, GPT-4o는 지시 사항을
정확하게 따르는 능력이 뛰어나, 이전 시스템들이 5-8개의 객체를 처리하는
데 어려움을 겪었던 반면, 최대 10-20개의 객체를 세부 사항까지 정확하게
구현할 수 있습니다.^21^

이러한 특성 때문에 GPT-4o의 최적 워크플로우는 하나의 완벽하고 거대한
프롬프트를 만드는 것이 아닙니다. 대신, 사용자는 생성 과정을 \'대화형
캔버스(Conversational Canvas)\'처럼 다루어야 합니다. 이는 기본 이미지를
먼저 생성한 후, \"배경을 숲으로 바꿔줘\", \"이제 그가 미소 짓게 해줘\",
\"같은 캐릭터를 유지하되 달리는 포즈로 변경해줘\"와 같은 자연어 대화를
통해 점진적으로 이미지를 수정하고 발전시키는 것을 의미합니다. 이
반복적이고 대화적인 접근 방식은 GPT-4o만의 고유한 강점이며, 경직된
\'프롬프트 입력/이미지 출력\' 시스템에 비해 캐릭터 일관성을 확보하는 데
있어 주요한 이점을 제공합니다.^19^ 따라서 이 플랫폼을 마스터하기
위해서는 단순히 프롬프트 공식을 배우는 것이 아니라, 이러한 \'과정\'
자체를 익혀야 합니다.

### **2.2. 시뮬레이션된 GenID: 이미지 업로드를 통한 인-컨텍스트 학습** {#시뮬레이션된-genid-이미지-업로드를-통한-인-컨텍스트-학습}

GPT-4o에서 일관성을 확보하는 가장 강력한 기술은 모델이 생성한 결과물이나
외부 이미지를 직접적인 참조물로 사용하는 것입니다.

GPT-4o는 Midjourney의 \--cref나 과거 DALL-E의 gen_id와 같은 명시적인
파라미터를 제공하지 않지만 ^23^, 업로드된 이미지를 통한 \'인-컨텍스트
학습(in-context learning)\' 기능으로 사실상 동일한 역할을
수행합니다.^21^ 사용자가 이미지를 업로드하면, GPT-4o는 해당 이미지의
스타일, 내용, 구성을 분석하고 이해하여 새로운 이미지를 생성할 때 시각적
참조점으로 활용합니다.^21^

이것이 바로 \'캐릭터 참조\' 기능을 시뮬레이션하는 가장 효과적인
방법입니다. 기준이 되는 캐릭터 이미지를 생성하거나 확보한 뒤, 동일한
채팅창에 해당 이미지를 업로드하고 새로운 장면이나 수정을 요청하는
것입니다.^22^ 모델의 깊은 시각적 맥락 이해 능력은 캐릭터의 외모를 후속
생성물에서도 일관되게 유지시켜 줍니다.^22^

**워크플로우:**

1.  **\'앵커(Anchor)\' 이미지 생성:** 상세한 \'DNA\' 프롬프트를 사용하여
    > 캐릭터의 특징이 명확하게 드러나는 정면 초상화를 생성합니다.

2.  **업로드 및 지시:** 생성된 앵커 이미지를 채팅창에 업로드합니다.

3.  **행동 프롬프트 작성:** 새로운 프롬프트에 원하는 행동을 묘사하되,
    > 업로드된 이미지를 명시적으로 참조하도록 지시합니다. 예를 들어,
    > 업로드된 이미지의 캐릭터를 사용하여, 그가 빽빽한 숲속을 달리는
    > 모습을 보여줘. 그의 외모와 복장은 정확히 유지해줘. 와 같은
    > 방식입니다.^21^

### **2.3. 파워 유저 전략: \'DNA 템플릿\'을 활용한 제어 극대화** {#파워-유저-전략-dna-템플릿을-활용한-제어-극대화}

최고 수준의 일관성을 보장하기 위한 가장 확실한 방법은 1.1절에서 다룬
\'DNA 템플릿\'과 2.1절의 \'대화형 캔버스\' 워크플로우를 결합하는
것입니다.

사용자들은 일련의 장면을 생성하기 전에, AI에게 필요한 모든 캐릭터 및
스타일 정보를 미리 주입하기 위해 고도로 구조화된 \'DNA 템플릿\'을
개발했습니다.^6^ 이 템플릿은 전체 대화 세션을 위한 마스터 지침서 역할을
합니다. 캐릭터의 정체성, 외모, 의상(여러 캐릭터를 위한 변형 포함), 표정,
아트 스타일, 조명, 구도 등을 총체적으로 정의합니다.^6^ 이 워크플로우의
핵심은 전체 템플릿을 대화의 첫머리에 붙여넣은 다음, AI의 컨텍스트
창(기억 능력)에 의존하여 장면별로 짧고 구체적인 프롬프트만 순차적으로
제공하는 것입니다.^6^

**단계별 가이드:**

1.  **마스터 DNA 템플릿 제작:** 1부의 표 1에 제시된 구조를 활용하여
    > 캐릭터와 세계관에 대한 상세한 프롬프트를 작성합니다.

2.  **세션 시작:** 새로운 채팅을 시작하고, 작성된 전체 DNA 템플릿을 첫
    > 번째 메시지로 붙여넣습니다. 그리고 이 규칙들을 이해했음을
    > 확인해줘. 이제부터 장면 설명을 하나씩 제공할게. 와 같은 지시로
    > 마무리합니다.

3.  **장면 프롬프트 제공:** 각 새로운 이미지에 대해서는 변화하는
    > 정보(주로 행동)만 간결하게 제공합니다. 예를 들어, 장면 1: 캐릭터가
    > 카페에 앉아 생각에 잠겨 있다. 와 같이 입력합니다.

4.  **반복 및 수정:** 만약 AI가 초기 지침에서 벗어나는 결과물을
    > 생성하면, 원래 템플릿을 참조하여 부드럽게 교정합니다. 예를 들어,
    > 거의 다 좋은데, DNA 템플릿에서 그의 재킷은 검은색이 아니라 짙은
    > 갈색이었던 것을 기억해줘. 올바른 재킷 색상으로 장면 1을 다시
    > 생성해줘. 와 같이 수정할 수 있습니다.^6^

## **3부: Google Imagen 4를 활용한 캐릭터 일관성 확보** {#부-google-imagen-4를-활용한-캐릭터-일관성-확보}

Google의 생태계는 전통적인 디지털 프로덕션 파이프라인과 유사한
*명시적(explicit)* 제어 워크플로우를 제공하는 데 강점을 보입니다. 이는
사용자가 창작 과정을 단계별로 명확하게 통제하기를 원할 때 유리합니다.

### **3.1. Imagen 4 생태계: Vertex AI, AI Studio, 그리고 Flow 탐색** {#imagen-4-생태계-vertex-ai-ai-studio-그리고-flow-탐색}

Imagen 4는 다양한 경로를 통해 접근할 수 있으며, 각 경로는 다른 목적을
가집니다. 이를 명확히 이해하는 것이 중요합니다.

2025년 기준으로 Imagen 4는 Google의 최상위 텍스트-이미지 모델이며, 특히
Imagen 4 Ultra 버전은 가장 높은 수준의 프롬프트 준수 능력을
보여줍니다.^26^ 이 모델은 Gemini API, Google AI Studio, 그리고
\'Flow\'라는 전문 영상 제작 도구를 통해 접근할 수 있습니다.^26^ 이
중에서 스토리텔링과 같은 서사적 작업에 가장 핵심적인 도구는

**Flow**입니다. Flow는 Google의 비디오 모델인 Veo와 이미지 모델인
Imagen을 위해 특별히 설계되었으며, **Scenebuilder**, 카메라 제어, 자산
관리(Asset Management)와 같은 기능을 포함하고 있습니다.^27^

Flow와 같은 도구의 존재는 Google의 개발 철학을 명확히 보여줍니다. 이는
단순히 그림을 그려주는 챗봇이 아니라, 하나의 완성된 \'프로덕션 환경\'을
지향합니다. 이 환경에서의 워크플로우는 대화형이 아닌 절차적입니다.
즉, 1) Imagen으로 캐릭터나 배경 같은 \'자산\'을 생성하고, 2) 이 자산들을
관리하며, 3) Scenebuilder를 사용해 자산들을 시퀀스로 조립하는
방식입니다. 이는 GPT-4o의 대화형 접근법과는 근본적으로 다르며,
애니메이터나 시각 효과 아티스트처럼 구조화되고 비선형적인 파이프라인
기반의 워크플로우를 선호하는 사용자에게 더 적합합니다.

### **3.2. 샷 연출: Flow와 Scenebuilder를 활용한 서사적 연속성 워크플로우** {#샷-연출-flow와-scenebuilder를-활용한-서사적-연속성-워크플로우}

Google의 전문 도구를 사용한 스토리텔링 워크플로우는 다음과 같은 개념적
과정을 따릅니다.

Flow 내에서 사용자는 텍스트를 통해 Imagen을 사용하여 캐릭터나 장면과
같은 \'재료(ingredients)\'를 생성할 수 있습니다.^27^ 핵심적으로, 이렇게
생성된 \'재료는 일관성을 유지하며 여러 다른 클립과 장면에 통합될 수
있습니다\'.^27^ 또한, 생성된 장면 이미지를 새로운 샷의 시작점으로
활용하는 것도 가능합니다.^27^ Scenebuilder는 \'지속적인 움직임과 일관된
캐릭터\'를 유지하면서 기존 샷을 편집하고 확장하는 기능을 제공하여 서사적
연속성을 보장합니다.^27^

**사용자 여정 (개념적):**

1.  **자산 생성:** Flow 내에서 Imagen을 사용하여 매우 구체적인
    > 프롬프트로 캐릭터의 고품질 이미지를 생성합니다. 이 이미지는 관리
    > 가능한 \'자산\'이 됩니다.

2.  **장면 1 생성:** Scenebuilder를 사용하여 첫 번째 샷을 만듭니다. 이는
    > 처음부터 프롬프트를 작성하고 캐릭터 자산을 통합하거나, 캐릭터
    > 이미지를 시작점으로 사용하여 생성할 수 있습니다.

3.  **장면 연결:** Scenebuilder의 \'확장(extend)\' 또는 \'점프(jump
    > to)\' 기능을 사용하여 다음 샷을 생성합니다. 이때 이전 샷의 캐릭터
    > 일관성을 유지하도록 명시적으로 지시합니다.^29^ 이는 이 도구가
    > 시퀀스 내의 이전 프레임을 참조하는 내장 메커니즘을 가지고 있음을
    > 시사합니다.

### **3.3. Imagen 4를 위한 정밀 프롬프팅: 명시적이고 상세한 지시의 기술** {#imagen-4를-위한-정밀-프롬프팅-명시적이고-상세한-지시의-기술}

Imagen 4는 GPT-4o의 유연한 대화 스타일과는 대조적으로, 매우 구체적이고
상세한 프롬프트를 요구합니다.

사용자 리뷰에 따르면, Imagen 4는 좋은 성능을 내기 위해 길고, 구체적이며,
상세한 프롬프트를 필요로 합니다.^30^ 단순한 프롬프트는 캐릭터 디테일이
부족한 저품질의 결과로 이어질 수 있습니다.^30^ 이 모델의 강점은 사진과
같은 사실적인 표현과, 감독의 샷 설명처럼 상세하게 서술된 장문 프롬프트를
해석하는 데 있습니다.^31^ 권장되는 프롬프트 구조는 이미지 유형(\"A photo
of\...\")으로 시작하여, 주제, 세부 사항, 배경, 그리고 카메라 렌즈, 위치,
조명과 같은 기술적 매개변수 순으로 작성하는 것입니다.^33^

여러 캐릭터가 등장하는 장면에서는 한 캐릭터의 속성이 다른 캐릭터에게
옮겨가거나, 두 번째, 세 번째 캐릭터의 묘사가 무시되는 \'속성 혼합\'
현상이 빈번하게 발생합니다.^4^ 이를 해결하기 위한 최선의 방법은 구조화된
형식을 사용하는 것이지만, 여전히 어려운 과제로 남아있습니다. NovelAI와
같은 고급 도구에서 사용되는 구문을 응용하여, 구분자(

\|)를 사용해 프롬프트를 명확히 분리하는 구조를 시도해볼 수 있습니다.
이는 모델이 각 주제를 더 잘 구별하도록 돕습니다.^36^

다중 캐릭터 프롬프트 구조 예시:

{기본 프롬프트: 스타일, 배경, 전반적인 행동} \| {캐릭터 1 프롬프트:
묘사, 특정 행동} \| {캐릭터 2 프롬프트: 묘사, 특정 행동}

### **3.4. 프롬프트를 넘어서: 스타일 튜닝과 시드 고정 개요** {#프롬프트를-넘어서-스타일-튜닝과-시드-고정-개요}

Imagen은 일관성 확보를 위해 프롬프팅 외에 더 기술적인 고급 기능들을
제공합니다.

Vertex AI 기반의 Imagen은 \*\*스타일 미세조정(style fine-tuning)\*\*을
지원합니다. 이를 통해 사용자는 특정 미학(예: \"황금빛 사진 스타일\")을
복제하기 위해 여러 이미지를 기반으로 맞춤형 모델을 훈련시킬 수
있습니다.^37^ 문서에서는 주로 스타일에 초점을 맞추고 있지만, 이론적으로
충분한 참조 이미지가 있다면 특정 \'캐릭터 스타일\' 모델을 만드는 데에도
응용할 수 있습니다.

또한, Google ImageFX(Imagen 기반)와 같은 플랫폼 사용자들은 생성물 간의
일관성을 유지하기 위해 **시드 번호(seed number)를 고정**하는 것의
중요성을 강조합니다.^1^ 시드 번호를 고정하면, 프롬프트가 약간만
변경되었을 때 이미지 생성의 기반이 되는 노이즈 패턴이 동일하게 유지되어
결과적으로 더 유사한 이미지를 얻을 수 있습니다.^38^ 이는 확산 모델에서
일관성을 확보하기 위한 근본적인 기술 중 하나입니다.

## **4부: 고급 교차 플랫폼 기술 및 워크플로우** {#부-고급-교차-플랫폼-기술-및-워크플로우}

이 파트에서는 특정 플랫폼에 국한되지 않고, 창의적인 기술 전문가가
어디서든 적용할 수 있는 보편적이고 전문적인 기술들을 다룹니다.

### **4.1. 감독의 툴킷: 카메라 앵글, 샷 유형, 시네마틱 조명을 이용한 고급 제어** {#감독의-툴킷-카메라-앵글-샷-유형-시네마틱-조명을-이용한-고급-제어}

단순한 이미지 생성을 넘어 의도적인 연출을 위해서는 프롬프트에 전문적인
영화 촬영 용어를 사용하여 \'감독처럼 생각하는\' 접근법이 필요합니다.

카메라 앵글(low-angle shot, high-angle shot, dutch angle), 샷
유형(extreme wide shot, medium close-up, cowboy shot), 그리고 카메라
움직임(tracking shot, crane shot)과 같은 영화적 단서를 사용하면 결과물의
품질과 서사적 느낌을 극적으로 향상시킬 수 있습니다.^39^ 프롬프트를
\'아름다운 영상\'과 같은 모호한 형용사로 시작하기보다는 \'\...의
오버헤드 드론 샷\'과 같이 구조적인 설명으로 시작하는 것이 훨씬
효과적입니다.^41^

조명은 분위기를 결정하는 데 매우 중요합니다. golden hour, dramatic
lighting, volumetric lighting, Rembrandt-inspired lighting과 같은
구체적인 조명 용어를 사용하면 원하는 감성과 분위기를 정확하게 전달할 수
있습니다.^12^

다음 표는 사용자가 구도와 분위기를 세밀하게 제어하여 단순한 생성을 넘어
의도적인 시네마틱 장면을 연출할 수 있도록 전문적인 용어를 제공합니다.
이는 여러 튜토리얼에서 언급된 용어들을 종합한 것입니다.^39^

**표 3: 시네마틱 프롬프팅 용어집**

| 제어 유형       | 용어                    | 효과 및 사용 사례                                                     |
|-----------------|-------------------------|-----------------------------------------------------------------------|
| **카메라 샷**   | Medium Close-Up (MCU)   | 표정에 집중하여 친밀감을 형성                                         |
|                 | Cowboy Shot             | 캐릭터의 자세와 얼굴 표정을 동시에 보여줌                             |
|                 | Extreme Wide Shot (EWS) | 광활한 배경을 통해 장면의 규모를 설정                                 |
| **카메라 앵글** | Low Angle Shot          | 피사체를 강력하고 영웅적으로 보이게 함                                |
|                 | High Angle Shot         | 피사체를 취약하게 보이게 하거나, 공간 관계를 설명                     |
|                 | Dutch Angle             | 심리적 긴장감이나 불안감을 조성                                       |
| **조명**        | Golden Hour             | 낭만적이거나 향수를 불러일으키는 장면에 이상적인 따뜻하고 부드러운 빛 |
|                 | Chiaroscuro Lighting    | 극적이고 분위기 있는 장면을 위한 고대비 조명                          |
|                 | Volumetric Lighting     | 빛줄기가 공기 중에서 보이는 효과로, 신비롭거나 극적인 분위기 연출     |

### **4.2. 애니메이터의 비밀: 포즈, 깊이, 스타일 복제를 위한 ControlNet 입문** {#애니메이터의-비밀-포즈-깊이-스타일-복제를-위한-controlnet-입문}

ControlNet은 텍스트 프롬프트 외에 추가적인 조건 레이어를 제공하여 생성
과정을 정밀하게 제어하는 기술입니다.

ControlNet은 참조 이미지로부터 포즈, 스타일, 깊이 정보 등을 추출하여
확산 모델을 추가적으로 제어하는 신경망입니다.^45^ 이 기술을 통해
사용자는 캐릭터의 \'정체성\'과 \'행동\'을 분리하여 제어할 수 있습니다.
강력한 텍스트 프롬프트와 참조 이미지로 정체성을 고정한 후, ControlNet을
사용하여 포즈를 정밀하게 지시하는 것입니다. 이러한 \'관심사 분리\'는
전문적인 애니메이션 및 시각 효과 파이프라인의 핵심 원리이며,
ControlNet은 이 강력한 기능을 프롬프팅 영역으로 가져옵니다.

주요 ControlNet 모델은 다음과 같습니다:

- **OpenPose:** 참조 이미지에서 골격 구조를 추출하여 캐릭터의 외모는
  > 바꾸지 않으면서 포즈만 정확하게 복제합니다.^5^ 이는 \'동일한
  > 캐릭터\'를 \'다른 행동\'으로 생성하는 핵심 기술입니다.

- **Canny/LineArt/SoftEdge:** 이미지의 외곽선과 윤곽을 추출하여,
  > 스타일이나 질감을 변경하면서도 캐릭터 디자인의 구도와 세부 사항을
  > 유지합니다.^5^

- **Depth:** 장면의 3D 공간 관계를 포착하여 캐릭터가 환경 내에 올바르게
  > 배치된 것처럼 보이게 합니다.^5^

고급 워크플로우에서는 여러 ControlNet을 결합하여 사용하기도 합니다. 예를
들어, 한 이미지는 포즈 참조용으로, 다른 이미지는 캐릭터 스타일
참조용으로 동시에 사용하는 것입니다.^47^ 이는 마치 텍스트 프롬프트가
\'대본\', 참조 이미지가 \'배우의 얼굴 사진\'이라면, ControlNet은
\'스토리보드\'나 \'사전 시각화\'와 같은 역할을 하는 \'구조적
비계(Structural Scaffold)\'를 제공하는 것과 같습니다. 이 비계는 확산
모델의 생성을 제약하여 사용자가 원하는 정밀한 결과를 얻도록 돕습니다.

### **4.3. 스토리텔러의 아크: 일관된 서사 시퀀스를 위한 프롬프트 체이닝** {#스토리텔러의-아크-일관된-서사-시퀀스를-위한-프롬프트-체이닝}

프롬프트 체이닝(Prompt Chaining)은 복잡한 서사를 더 작고 관리하기 쉬운
여러 개의 프롬프트로 나누어 순차적으로 연결하는 기술입니다.

이 기술은 한 프롬프트의 출력이 다음 프롬프트의 입력이 되는 방식으로
작동하며, 하나의 거대한 프롬프트로는 처리하기 어려운 복잡한 작업을
수행하는 데 필수적입니다.^48^ 이는 단순히 이야기를 여러 부분으로 나누는
것을 넘어, 프로그래밍과 문제 해결의 기본 개념인 \'논리적 분해(Logical
Decomposition)\'를 적용하는 것입니다.^49^ 복잡한 시각적 서사를
개별적이고 관리 가능한 단계로 분해함으로써, 사용자는 단일 생성에 대한
AI의 인지 부하를 줄일 수 있습니다. 이는 오류를 최소화하고, 세부 사항
준수율을 높이며, 각 단계에서 품질을 관리하고 수정할 수 있는 기회를
제공합니다.^48^ 이로써 사용자는 단순한 \'프롬프터\'에서 벗어나, 복잡한
창작 결과를 향한 논리적 경로를 설계하는 \'워크플로우 설계자\'가 됩니다.

**서사 시퀀스를 위한 워크플로우:**

1.  **서사 계획:** 이야기를 핵심적인 \'비트(beat)\' 또는 장면 단위로
    > 나눕니다.^41^

2.  **프롬프트 1 (설정):** 첫 장면을 생성합니다. 예: \... 캐릭터가 먼지
    > 쌓인 도서관에서 낡은 지도를 발견한다.

3.  **프롬프트 2 (진행):** 프롬프트 1의 결과물(GPT-4o의 경우 암묵적
    > 맥락, 다른 경우 명시적 참조 이미지)을 기반으로 다음 비트를
    > 생성합니다. 예: 지도를 따라, 캐릭터는 이제 짙고 안개 낀 숲을
    > 통과하고 있다.

4.  **프롬프트 3 (클라이맥스):** 체인을 계속 이어갑니다. 예: 캐릭터가
    > 숲에서 빠져나오자 지도가 가리키던 고대 유적이 눈앞에
    > 나타난다..^41^

## **5부: 분석, 문제 해결 및 미래 전망** {#부-분석-문제-해결-및-미래-전망}

이 마지막 파트에서는 실용적인 조언, 플랫폼 간의 직접적인 비교, 그리고
기술의 미래에 대한 전망을 제공합니다.

### **5.1. 일반적인 함정과 해결책: 기형적인 손, 속성 혼합, 스타일 변형 문제 해결** {#일반적인-함정과-해결책-기형적인-손-속성-혼합-스타일-변형-문제-해결}

가장 빈번하게 발생하는 문제들에 대한 집중적인 해결 가이드는 다음과
같습니다.

- **기형적인 손:** 손의 복잡한 해부학적 구조와 훈련 데이터의 다양성
  > 때문에 악명 높은 문제입니다.^51^

  - **해결책 1 (프롬프팅):** extra fingers, mutated hands, poorly drawn
    > hands와 같은 강력한 네거티브 프롬프트를 사용합니다.^14^

  - **해결책 2 (후처리):** 인페인팅/아웃페인팅 도구를 활용합니다. 가장
    > 효과적인 방법은 올가미 도구 등으로 잘못된 손을 선택한 후,
    > Photoshop AI의 생성형 채우기 같은 기능에 \"완벽한 형태의 손\"과
    > 같은 간단한 프롬프트나 심지어 빈 프롬프트를 입력하여 AI가 맥락에
    > 맞게 수정하도록 하는 것입니다.^51^

  - **해결책 3 (고급):** MeshGraphormer와 같은 전문화된 ControlNet
    > 전처리기를 사용하여 손의 깊이 맵을 생성하고, 이를 기반으로 더
    > 정확하게 손을 다시 그리도록 유도합니다.^55^

- **속성 혼합 및 스타일 변형:** 다중 캐릭터 장면이나 여러 세대에 걸쳐
  > 생성할 때 모델이 혼란을 겪으며 발생하는 문제입니다. 해결책은 이미
  > 논의된 기술들, 즉 고도로 구조화된 프롬프트 사용 ^36^, \'DNA
  > 템플릿\'의 반복적 강화 ^6^, 그리고 참조 이미지의 적극적인 활용에
  > 있습니다.^5^

### **5.2. 비교 분석: ChatGPT-4o 대 Imagen 4의 강점과 약점** {#비교-분석-chatgpt-4o-대-imagen-4의-강점과-약점}

사용자가 특정 프로젝트의 목표와 선호하는 워크플로우에 따라 최적의 도구를
선택할 수 있도록 두 플랫폼을 직접 비교합니다.

- **ChatGPT-4o 강점:** 뛰어난 맥락 이해와 대화형 수정 능력 덕분에
  > 반복적인 디자인과 창의적인 브레인스토밍에 이상적입니다. 업로드된
  > 이미지로부터의 인-컨텍스트 학습 능력이 강력하며, 이미지 내 텍스트
  > 렌더링에 탁월합니다.^19^ 이 플랫폼의 핵심은  
  > **유연성**입니다.

- **ChatGPT-4o 약점:** 이미지 생성 속도가 느릴 수 있으며, 일관성은 전용
  > 기능이 아닌 사용자의 대화 맥락 관리에 의존합니다.^22^

- **Imagen 4 강점:** 고품질의 사실적인 결과물에 특화되어 있으며, 길고
  > 지시적인 프롬프트에 잘 반응합니다. Flow 도구는 서사적 시퀀싱을 위한
  > 구조화된 파이프라인 기반 접근법을 제공합니다.^27^ 이 플랫폼의
  > 핵심은  
  > **정밀성과 품질**입니다.

- **Imagen 4 약점:** 일반 사용자에게는 덜 직관적이며, 좋은 결과를 얻기
  > 위해 매우 구체적이고 상세한 프롬프트를 요구합니다. 꼼꼼하게
  > 프롬프트를 작성하지 않으면 캐릭터 세부 사항을 놓치는 경향이
  > 있습니다.^30^

다음 표는 이 보고서의 분석 결과를 요약하여, 사용자가 정보에 기반한
결정을 내릴 수 있도록 돕습니다.^19^

**표 4: 플랫폼 비교 - 캐릭터 일관성을 위한 ChatGPT-4o 대 Google Imagen
4**

| 구분                 | ChatGPT-4o                                | Google Imagen 4                          |
|----------------------|-------------------------------------------|------------------------------------------|
| **핵심 일관성 방법** | 대화형 맥락 및 이미지 업로드              | 자산 참조 및 장면 연결                   |
| **프롬프팅 스타일**  | 반복적 및 자연어                          | 명시적 및 고도로 상세함                  |
| **제어 수준**        | 암묵적 / 협업적                           | 명시적 / 지시적                          |
| **최적 사용 사례**   | 창의적 탐색, 스토리보딩, 캐릭터 컨셉 구상 | 영화적 최종 샷, 전문 프로덕션 파이프라인 |
| **주요 약점**        | 신중한 대화 관리가 필요함                 | 가파른 학습 곡선, 모호한 프롬프트에 취약 |
| **지원 도구**        | 네이티브 채팅 인터페이스                  | Flow, Scenebuilder, AI Studio            |

### **5.3. 앞으로의 길: 최신 연구와 정체성 보존의 미래** {#앞으로의-길-최신-연구와-정체성-보존의-미래}

학술 연구의 최전선을 살펴봄으로써 기술이 나아갈 방향을 예측할 수
있습니다.

학계는 캐릭터 일관성을 주요 도전 과제로 인식하고 집중적으로 연구하고
있습니다.^57^

**1Prompt1Story**와 같은 새로운 기술은 모든 프레임 설명을 하나의 거대한
프롬프트로 연결한 후, 특이값 재가중(SVR)이나 정체성 보존
교차-어텐션(IPCA) 같은 새로운 기법을 사용하여 각 프레임의 결과물을
정제하는 방식을 제안합니다.^59^ 이는 언어 모델이 본질적으로 가진 맥락
일관성 능력을 활용하는 접근법입니다.

다른 연구들은 2D 이미지 생성을 넘어, 가우시안 스플래팅(Gaussian
Splatting)이나 NeRFs와 같은 3D 자산을 생성하여 진정한 의미의 공간적,
시간적 일관성을 확보하는 데 초점을 맞추고 있습니다.^57^ 또한, 얼굴
일관성 벤치마크(FCB)와 같은 전용 평가 기준의 개발은 기술 발전을
표준화하고 가속화할 것입니다.^58^

이러한 연구 동향은 \'일관성 확보의 필연적인 추상화\'를 예고합니다. 현재
사용자들이 활용하는 DNA 템플릿, 시드 고정 같은 기법이나 플랫폼에서
제공하는 이미지 참조, Flow 같은 기능들은 과도기적 단계에 해당합니다.
연구가 가리키는 미래는 사용자가 모든 샷에 대해 수동으로 일관성을 설계할
필요가 없는 세상입니다. 대신, 몇 개의 참조 이미지를 제공하거나 상세한
텍스트 설명을 한 번 입력하면, 모델 자체가 모든 프롬프트에 걸쳐 정체성
보존을 자동으로 처리하게 될 것입니다. 이 보고서에서 논의된 복잡한
프롬프트 체이닝과 참조 이미지 업로드 워크플로우는 2025년의 최첨단
기술이지만, 이는 일관성이 사용자가 숙달해야 할 기술이 아니라 모델에
내장된 추상화된 기능이 될 미래를 향한 길을 닦고 있는 것입니다. 따라서 이
보고서는 빠르게 진화하는 한 분야의 현재를 담은 스냅샷이라 할 수
있습니다.

#### 참고 자료

1.  How to Make AI Consistent Characters for Free with Google Image
    > \..., 7월 28, 2025에 액세스,
    > [[https://dicloak.com/video-insights-detail/how-to-make-ai-consistent-characters-for-free-with-google-image-fx-free-ai-image-generator]{.underline}](https://dicloak.com/video-insights-detail/how-to-make-ai-consistent-characters-for-free-with-google-image-fx-free-ai-image-generator)

2.  Create Consistent Characters with AI: 2025 Guide - Atlabs AI, 7월
    > 28, 2025에 액세스,
    > [[https://www.atlabs.ai/blog/create-consistent-characters-with-ai-2025-guide]{.underline}](https://www.atlabs.ai/blog/create-consistent-characters-with-ai-2025-guide)

3.  The Best AI Image Regenerator For Consistent Characters in 2025, 7월
    > 28, 2025에 액세스,
    > [[https://demodazzle.com/blog/the-best-ai-image-regenerator-for-consistent-characters]{.underline}](https://demodazzle.com/blog/the-best-ai-image-regenerator-for-consistent-characters)

4.  \[Guide\] How to create consistent characters with DALL-E 3 :
    > r/dndai - Reddit, 7월 28, 2025에 액세스,
    > [[https://www.reddit.com/r/dndai/comments/179wd1f/guide_how_to_create_consistent_characters_with/]{.underline}](https://www.reddit.com/r/dndai/comments/179wd1f/guide_how_to_create_consistent_characters_with/)

5.  How to Design Consistent AI Characters with Prompts, Diffusion \...,
    > 7월 28, 2025에 액세스,
    > [[https://medium.com/design-bootcamp/how-to-design-consistent-ai-characters-with-prompts-diffusion-reference-control-2025-a1bf1757655d]{.underline}](https://medium.com/design-bootcamp/how-to-design-consistent-ai-characters-with-prompts-diffusion-reference-control-2025-a1bf1757655d)

6.  Need for Character Consistency and Style Locking in Image \..., 7월
    > 28, 2025에 액세스,
    > [[https://community.openai.com/t/need-for-character-consistency-and-style-locking-in-image-generation/1232362]{.underline}](https://community.openai.com/t/need-for-character-consistency-and-style-locking-in-image-generation/1232362)

7.  Diffusion Models for Image Generation -- A Comprehensive Guide -
    > LearnOpenCV, 7월 28, 2025에 액세스,
    > [[https://learnopencv.com/image-generation-using-diffusion-models/]{.underline}](https://learnopencv.com/image-generation-using-diffusion-models/)

8.  Introduction to Diffusion Models for Machine Learning - AssemblyAI,
    > 7월 28, 2025에 액세스,
    > [[https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction]{.underline}](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction)

9.  Transformer (deep learning architecture) - Wikipedia, 7월 28, 2025에
    > 액세스,
    > [[https://en.wikipedia.org/wiki/Transformer\_(deep_learning_architecture)]{.underline}](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture))

10. LLM Transformer Model Visually Explained - Polo Club of Data
    > Science, 7월 28, 2025에 액세스,
    > [[https://poloclub.github.io/transformer-explainer/]{.underline}](https://poloclub.github.io/transformer-explainer/)

11. The Attention Mechanism of LLMs Explained \| by M \| Foundation
    > \..., 7월 28, 2025에 액세스,
    > [[https://medium.com/foundation-models-deep-dive/attention-part-1-of-5-the-attention-revolution-understanding-the-core-of-modern-ai-2577f894d61a]{.underline}](https://medium.com/foundation-models-deep-dive/attention-part-1-of-5-the-attention-revolution-understanding-the-core-of-modern-ai-2577f894d61a)

12. Ultimate ChatGPT Image Prompts Guide 2025: Mastering AI Image
    > Generation - Cursor IDE, 7월 28, 2025에 액세스,
    > [[https://www.cursor-ide.com/blog/chatgpt-image-prompts-guide-2025]{.underline}](https://www.cursor-ide.com/blog/chatgpt-image-prompts-guide-2025)

13. Prompt Inversion for Text-to-Image Diffusion Models - UBC Computer
    > Science - The University of British Columbia, 7월 28, 2025에
    > 액세스,
    > [[https://www.cs.ubc.ca/\~lsigal/Publications/mahajan2024cvpr.pdf]{.underline}](https://www.cs.ubc.ca/~lsigal/Publications/mahajan2024cvpr.pdf)

14. Fixing Deformed AI Generations: Improve AI Image Quality - Learn
    > Prompting, 7월 28, 2025에 액세스,
    > [[https://learnprompting.org/docs/image_prompting/fix_deformed_generations]{.underline}](https://learnprompting.org/docs/image_prompting/fix_deformed_generations)

15. 120+ Stable Diffusion Negative Prompts to Improve AI Art in 2025,
    > 7월 28, 2025에 액세스,
    > [[https://clickup.com/blog/stable-diffusion-negative-prompts/]{.underline}](https://clickup.com/blog/stable-diffusion-negative-prompts/)

16. How to Use AI Negative Prompts for Better Outputs (+Examples) -
    > ClickUp, 7월 28, 2025에 액세스,
    > [[https://clickup.com/blog/ai-negative-prompt-examples/]{.underline}](https://clickup.com/blog/ai-negative-prompt-examples/)

17. Are there any universal negative prompts that can be used with any
    > generation? : r/StableDiffusion - Reddit, 7월 28, 2025에 액세스,
    > [[https://www.reddit.com/r/StableDiffusion/comments/zwd0y8/are_there_any_universal_negative_prompts_that_can/]{.underline}](https://www.reddit.com/r/StableDiffusion/comments/zwd0y8/are_there_any_universal_negative_prompts_that_can/)

18. List of Negative Prompts for Stable Diffusion - Novita AI Blog, 7월
    > 28, 2025에 액세스,
    > [[https://blogs.novita.ai/list-of-negative-prompts-for-stable-diffusion/]{.underline}](https://blogs.novita.ai/list-of-negative-prompts-for-stable-diffusion/)

19. ChatGPT-4o Image Creation Mastery: Complete Guide to Professional AI
    > Visuals in 2025, 7월 28, 2025에 액세스,
    > [[https://www.cursor-ide.com/blog/chatgpt-4o-image-creation-mastery-2025]{.underline}](https://www.cursor-ide.com/blog/chatgpt-4o-image-creation-mastery-2025)

20. ChatGPT Model Comparison: 4o vs o1 vs o3-mini vs 4.5 (2025 Guide) -
    > Jonathan Mast, 7월 28, 2025에 액세스,
    > [[https://jonathanmast.com/chatgpt-model-comparison-4o-vs-o1-vs-o3-mini-vs-4-5-2025-guide/]{.underline}](https://jonathanmast.com/chatgpt-model-comparison-4o-vs-o1-vs-o3-mini-vs-4-5-2025-guide/)

21. Introducing 4o Image Generation - OpenAI, 7월 28, 2025에 액세스,
    > [[https://openai.com/index/introducing-4o-image-generation/]{.underline}](https://openai.com/index/introducing-4o-image-generation/)

22. ChatGPT GPT-4o Image Generator: Complete 2025 Review & Guide, 7월
    > 28, 2025에 액세스,
    > [[https://mymeet.ai/blog/chatgpt-gpt4o-image-generator]{.underline}](https://mymeet.ai/blog/chatgpt-gpt4o-image-generator)

23. How to achieve consistency of comic characters - API - OpenAI
    > Developer Community, 7월 28, 2025에 액세스,
    > [[https://community.openai.com/t/how-to-achieve-consistency-of-comic-characters/591652]{.underline}](https://community.openai.com/t/how-to-achieve-consistency-of-comic-characters/591652)

24. DALL-E 3 Creates CONSISTENT Characters with One Click! - YouTube,
    > 7월 28, 2025에 액세스,
    > [[https://m.youtube.com/watch?v=4icS4OpC3Uo]{.underline}](https://m.youtube.com/watch?v=4icS4OpC3Uo)

25. Best ChatGPT Image Generation Prompts -- Prompt Guide for Creating
    > GPT-4o Images, 7월 28, 2025에 액세스,
    > [[https://upsampler.com/blog/best-chatgpt-image-generation-prompts]{.underline}](https://upsampler.com/blog/best-chatgpt-image-generation-prompts)

26. Imagen 4 is now available in the Gemini API and Google AI Studio,
    > 7월 28, 2025에 액세스,
    > [[https://developers.googleblog.com/en/imagen-4-now-available-in-the-gemini-api-and-google-ai-studio/]{.underline}](https://developers.googleblog.com/en/imagen-4-now-available-in-the-gemini-api-and-google-ai-studio/)

27. Introducing Flow: Google\'s AI filmmaking tool designed for Veo, 7월
    > 28, 2025에 액세스,
    > [[https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/]{.underline}](https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/)

28. Image generation \| Gemini API \| Google AI for Developers, 7월 28,
    > 2025에 액세스,
    > [[https://ai.google.dev/gemini-api/docs/image-generation]{.underline}](https://ai.google.dev/gemini-api/docs/image-generation)

29. Google\'s Veo 3: A Guide With Practical Examples - DataCamp, 7월 28,
    > 2025에 액세스,
    > [[https://www.datacamp.com/tutorial/veo-3]{.underline}](https://www.datacamp.com/tutorial/veo-3)

30. I Tested Imagen 4: Not as Good as Imagen 3, But Here\'s How to Get
    > the Best out of It!, 7월 28, 2025에 액세스,
    > [[https://pollo.ai/hub/imagen-4-review]{.underline}](https://pollo.ai/hub/imagen-4-review)

31. Character Consistency with 4o Image Generation - YouTube, 7월 28,
    > 2025에 액세스,
    > [[https://www.youtube.com/watch?v=PFsOUNfBhzI]{.underline}](https://www.youtube.com/watch?v=PFsOUNfBhzI)

32. Imagen - Google DeepMind, 7월 28, 2025에 액세스,
    > [[https://deepmind.google/models/imagen/]{.underline}](https://deepmind.google/models/imagen/)

33. Prompt and image attribute guide \| Generative AI on Vertex AI -
    > Google Cloud, 7월 28, 2025에 액세스,
    > [[https://cloud.google.com/vertex-ai/generative-ai/docs/image/img-gen-prompt-guide]{.underline}](https://cloud.google.com/vertex-ai/generative-ai/docs/image/img-gen-prompt-guide)

34. How to Use ImageFX, Google AI Image Generator - Content Beta, 7월
    > 28, 2025에 액세스,
    > [[https://www.contentbeta.com/blog/google-image-generator/]{.underline}](https://www.contentbeta.com/blog/google-image-generator/)

35. Multi-Character Prompting Suggestions for DALL-E image creation, 7월
    > 28, 2025에 액세스,
    > [[https://community.openai.com/t/multi-character-prompting-suggestions-for-dall-e-image-creation/443240]{.underline}](https://community.openai.com/t/multi-character-prompting-suggestions-for-dall-e-image-creation/443240)

36. Multi-Character Prompting - NovelAI Documentation, 7월 28, 2025에
    > 액세스,
    > [[https://docs.novelai.net/image/multiplecharacters.html]{.underline}](https://docs.novelai.net/image/multiplecharacters.html)

37. Tune a custom style model \| Generative AI on Vertex AI - Google
    > Cloud, 7월 28, 2025에 액세스,
    > [[https://cloud.google.com/vertex-ai/generative-ai/docs/image/fine-tune-style]{.underline}](https://cloud.google.com/vertex-ai/generative-ai/docs/image/fine-tune-style)

38. Consistent Image generation for Story using DALLE - API - OpenAI
    > Developer Community, 7월 28, 2025에 액세스,
    > [[https://community.openai.com/t/consistent-image-generation-for-story-using-dalle/612276]{.underline}](https://community.openai.com/t/consistent-image-generation-for-story-using-dalle/612276)

39. \"Cinematic & Photorealistic Ai Image Prompts! - Complete Guide -
    > Midjourney\" - Full Transcript Inside! \| YTScribe, 7월 28, 2025에
    > 액세스,
    > [[https://ytscribe.com/v/HWOLsh-7ZHQ]{.underline}](https://ytscribe.com/v/HWOLsh-7ZHQ)

40. Master Guide to Camera Angles and Shot Types for AI Generation -
    > MimicPC, 7월 28, 2025에 액세스,
    > [[https://www.mimicpc.com/learn/master-guide-to-camera-angles-and-shot-types-for-AI-image-and-video-generation]{.underline}](https://www.mimicpc.com/learn/master-guide-to-camera-angles-and-shot-types-for-AI-image-and-video-generation)

41. Want cinematic-looking AI videos? Try these 5 prompt techniques -
    > Hindustan Times, 7월 28, 2025에 액세스,
    > [[https://www.hindustantimes.com/technology/want-cinematic-looking-ai-videos-try-these-5-prompt-techniques-101751363119728.html]{.underline}](https://www.hindustantimes.com/technology/want-cinematic-looking-ai-videos-try-these-5-prompt-techniques-101751363119728.html)

42. 15 Prompts to Generate Better ChatGPT & Dall-e Images - Manticore
    > Marketing, 7월 28, 2025에 액세스,
    > [[https://www.manticoremarketing.com/blog/15-prompts-to-generate-better-chatgpt-dall-e-images]{.underline}](https://www.manticoremarketing.com/blog/15-prompts-to-generate-better-chatgpt-dall-e-images)

43. 10 Viral ChatGPT Prompts For Image Generation, 7월 28, 2025에
    > 액세스,
    > [[https://www.godofprompt.ai/blog/chatgpt-prompts-for-image-generation]{.underline}](https://www.godofprompt.ai/blog/chatgpt-prompts-for-image-generation)

44. Gen-4 Image Prompting Guide - Runway, 7월 28, 2025에 액세스,
    > [[https://help.runwayml.com/hc/en-us/articles/35694045317139-Gen-4-Image-Prompting-Guide]{.underline}](https://help.runwayml.com/hc/en-us/articles/35694045317139-Gen-4-Image-Prompting-Guide)

45. How to use ControlNet? (Detailed Explanation) - Stable Diffusion
    > Tutorials, 7월 28, 2025에 액세스,
    > [[https://www.stablediffusiontutorials.com/2024/01/controlnet-full-guide.html]{.underline}](https://www.stablediffusiontutorials.com/2024/01/controlnet-full-guide.html)

46. The Ultimate Guide to ControlNet (Part 1) - Civitai Education Hub,
    > 7월 28, 2025에 액세스,
    > [[https://education.civitai.com/civitai-guide-to-controlnet/]{.underline}](https://education.civitai.com/civitai-guide-to-controlnet/)

47. Reference Images: The Secret to AI Consistency \| Scenario, 7월 28,
    > 2025에 액세스,
    > [[https://help.scenario.com/en/articles/use-reference-images-for-enhanced-control/]{.underline}](https://help.scenario.com/en/articles/use-reference-images-for-enhanced-control/)

48. Chaining Prompts - Cohere, 7월 28, 2025에 액세스,
    > [[https://cohere.com/llmu/chaining-prompts]{.underline}](https://cohere.com/llmu/chaining-prompts)

49. Prompt Chaining: Your Gemini Power-Up for Mastering Complex Tasks \|
    > by Leon Nicholls, 7월 28, 2025에 액세스,
    > [[https://leonnicholls.medium.com/prompt-chaining-your-gemini-power-up-for-mastering-complex-tasks-8f373614692f]{.underline}](https://leonnicholls.medium.com/prompt-chaining-your-gemini-power-up-for-mastering-complex-tasks-8f373614692f)

50. optiwebdesign.com, 7월 28, 2025에 액세스,
    > [[https://optiwebdesign.com/2025/05/07/how-to-chain-prompts-in-kaiber-ai-step-by-step-guide/]{.underline}](https://optiwebdesign.com/2025/05/07/how-to-chain-prompts-in-kaiber-ai-step-by-step-guide/)

51. AI Hand Fixer: How to Fix AI Hands & Fingers in AI Art \[FREE\] -
    > Perfect Corp., 7월 28, 2025에 액세스,
    > [[https://www.perfectcorp.com/consumer/blog/generative-AI/fix-ai-hands]{.underline}](https://www.perfectcorp.com/consumer/blog/generative-AI/fix-ai-hands)

52. How to fix prompts for AI-generated images of hands :
    > r/StableDiffusion - Reddit, 7월 28, 2025에 액세스,
    > [[https://www.reddit.com/r/StableDiffusion/comments/10ce88i/how_to_fix_prompts_for_aigenerated_images_of_hands/]{.underline}](https://www.reddit.com/r/StableDiffusion/comments/10ce88i/how_to_fix_prompts_for_aigenerated_images_of_hands/)

53. Fix Bad Looking AI Hands & Fingers Using FREE Tools Like Fooocus AI
    > and Firefly AI, 7월 28, 2025에 액세스,
    > [[https://www.youtube.com/watch?v=pfr7W-Kr9is]{.underline}](https://www.youtube.com/watch?v=pfr7W-Kr9is)

54. How to Use Photoshop AI Generative Fill in 2025 (Detailed Tutorial),
    > 7월 28, 2025에 액세스,
    > [[https://www.elegantthemes.com/blog/design/photoshop-ai]{.underline}](https://www.elegantthemes.com/blog/design/photoshop-ai)

55. How to Fix Hands in AI-Generated Images with MeshGraphormer -
    > RunComfy, 7월 28, 2025에 액세스,
    > [[https://learn.runcomfy.com/fix-hands-in-ai-art-with-comfyui-a-stepbystep-guide]{.underline}](https://learn.runcomfy.com/fix-hands-in-ai-art-with-comfyui-a-stepbystep-guide)

56. Midjourney vs. ChatGPT (formerly DALL·E 3): Which image generator is
    > better? \[2025\], 7월 28, 2025에 액세스,
    > [[https://zapier.com/blog/midjourney-vs-dalle/]{.underline}](https://zapier.com/blog/midjourney-vs-dalle/)

57. Generative AI for Film Creation: A Survey of Recent Advances -
    > arXiv, 7월 28, 2025에 액세스,
    > [[https://arxiv.org/html/2504.08296v1]{.underline}](https://arxiv.org/html/2504.08296v1)

58. \[2505.11425\] Face Consistency Benchmark for GenAI Video - arXiv,
    > 7월 28, 2025에 액세스,
    > [[https://arxiv.org/abs/2505.11425]{.underline}](https://arxiv.org/abs/2505.11425)

59. One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation
    > Using a Single Prompt - arXiv, 7월 28, 2025에 액세스,
    > [[https://arxiv.org/pdf/2501.13554?]{.underline}](https://arxiv.org/pdf/2501.13554)

60. One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation
    > Using a Single Prompt \| OpenReview, 7월 28, 2025에 액세스,
    > [[https://openreview.net/forum?id=cD1kl2QKv1]{.underline}](https://openreview.net/forum?id=cD1kl2QKv1)
